import os
import logging
from pyspark.sql import SparkSession
from pyspark.sql.functions import *
from pyspark.sql.types import *

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def _parse_endpoint(endpoint: str):
    """
    Retourne (host:port, secure_bool) depuis une URL comme http://minio:9000 ou minio:9000
    """
    from urllib.parse import urlparse
    if not endpoint:
        return "minio:9000", False
    parsed = urlparse(endpoint if "://" in endpoint else f"http://{endpoint}")
    host = f"{parsed.hostname}:{parsed.port or 9000}"
    secure = parsed.scheme == "https"
    return host, secure

def create_spark_session():
    """Cr√©er une session Spark configur√©e pour MinIO (s3a) et Delta Lake"""
    endpoint = os.environ.get("MINIO_ENDPOINT", "http://minio:9000")
    access_key = os.environ.get("MINIO_ACCESS_KEY", "minioadmin")
    secret_key = os.environ.get("MINIO_SECRET_KEY", "minioadmin123")

    host_port, secure = _parse_endpoint(endpoint)

    builder = SparkSession.builder \
        .appName("Create Delta Tables - Healthcare Data") \
        .config("spark.hadoop.fs.s3a.endpoint", f"http://{host_port}" if not secure else f"https://{host_port}") \
        .config("spark.hadoop.fs.s3a.access.key", access_key) \
        .config("spark.hadoop.fs.s3a.secret.key", secret_key) \
        .config("spark.hadoop.fs.s3a.path.style.access", "true") \
        .config("spark.hadoop.fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem") \
        .config("spark.hadoop.fs.s3a.connection.ssl.enabled", "true" if secure else "false") \
        .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension") \
        .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog") \
        .config("spark.sql.adaptive.enabled", "true") \
        .config("spark.sql.adaptive.coalescePartitions.enabled", "true")

    return builder.getOrCreate()

def create_delta_tables(spark):
    """Cr√©er toutes les tables Delta selon le sch√©ma d√©fini"""
    logger.info("üöÄ Cr√©ation des tables Delta Healthcare...")
    
    # =================================
    # TABLES DE DIMENSIONS
    # =================================
    
    # Dimension des lieux
    logger.info("Cr√©ation de la table dim_lieu...")
    spark.sql("""
        CREATE TABLE IF NOT EXISTS delta.`s3a://healthcare-data/gold/dim_lieu` (
            lieu_id INT COMMENT 'Identifiant du lieu',
            commune STRING COMMENT 'Nom de la commune',
            departement STRING COMMENT 'Code du d√©partement',
            region STRING COMMENT 'R√©gion administrative',
            pays STRING COMMENT 'Pays'
        )
        USING DELTA
        PARTITIONED BY (region)
        LOCATION 's3a://healthcare-data/gold/dim_lieu'
    """)
    
    # Dimension des patients
    logger.info("Cr√©ation de la table dim_patient...")
    spark.sql("""
        CREATE TABLE IF NOT EXISTS delta.`s3a://healthcare-data/gold/dim_patient` (
            patient_id INT COMMENT 'Identifiant du patient',
            age INT COMMENT '√Çge du patient',
            sexe STRING COMMENT 'Sexe du patient',
            annee_naissance INT COMMENT 'Ann√©e de naissance', ## Utile pour la partition
            date_naissance DATE COMMENT 'Date de naissance'
        )
        USING DELTA
        PARTITIONED BY (annee_naissance)
        LOCATION 's3a://healthcare-data/gold/dim_patient'
    """)
    
    # Dimension des dates
    logger.info("Cr√©ation de la table dim_date...")
    spark.sql("""
        CREATE TABLE IF NOT EXISTS delta.`s3a://healthcare-data/gold/dim_date` (
            date_id INT COMMENT 'Identifiant de la date',
            date_complete DATE COMMENT 'Date compl√®te',
            annee INT COMMENT 'Ann√©e',
            mois INT COMMENT 'Mois',
            jour INT COMMENT 'Jour',
            trimestre INT COMMENT 'Trimestre',
            semestre INT COMMENT 'Semestre'
        )   
        USING DELTA
        PARTITIONED BY (annee)
        LOCATION 's3a://healthcare-data/gold/dim_date'
    """)
    
    # Dimension des √©tablissements de sant√©
    logger.info("Cr√©ation de la table dim_etablissement...")
    spark.sql("""
        CREATE TABLE IF NOT EXISTS delta.`s3a://healthcare-data/gold/dim_etablissement` (
            etablissement_id INT COMMENT 'Identifiant √©tablissement',
            raison_sociale STRING COMMENT 'Raison sociale',
            adresse STRING COMMENT 'Adresse postale',
            commune STRING COMMENT 'Commune',
            code_postal STRING COMMENT 'Code postal',
            region STRING COMMENT 'R√©gion'
        )
        USING DELTA
        PARTITIONED BY (region)
        LOCATION 's3a://healthcare-data/gold/dim_etablissement'
    """)
    
    # Dimension des diagnostics
    logger.info("Cr√©ation de la table dim_diagnostic...")
    spark.sql("""
        CREATE TABLE IF NOT EXISTS delta.`s3a://healthcare-data/gold/dim_diagnostic` (
            diagnostic_id STRING COMMENT 'Code diagnostic',
            libelle_diagnostic STRING COMMENT 'Libell√© du diagnostic',
            categorie_diagnostic STRING COMMENT 'Cat√©gorie du diagnostic'
        )   
        USING DELTA
        PARTITIONED BY (categorie_diagnostic)
        LOCATION 's3a://healthcare-data/gold/dim_diagnostic'
    """)
    
    # Dimension des indicateurs de satisfaction
    logger.info("Cr√©ation de la table dim_indicateur...")
    spark.sql("""
        CREATE TABLE IF NOT EXISTS delta.`s3a://healthcare-data/gold/dim_indicateur` (
            indicateur_id INT COMMENT 'Identifiant indicateur',
            libelle_indicateur STRING COMMENT 'Libell√© de l'indicateur',
            categorie_indicateur STRING COMMENT 'Cat√©gorie de l'indicateur'
        )
        USING DELTA
        PARTITIONED BY (categorie_indicateur)
        LOCATION 's3a://healthcare-data/gold/dim_indicateur'
    """)
    
    # Dimension des professionnels de sant√©
    logger.info("Cr√©ation de la table dim_professionel...")
    spark.sql("""
        CREATE TABLE IF NOT EXISTS delta.`s3a://healthcare-data/gold/dim_professionel` (
            professionnel_id INT COMMENT 'Identifiant professionnel de sant√©',
            nom STRING COMMENT 'Nom',
            prenom STRING COMMENT 'Pr√©nom',
            civilite STRING COMMENT 'Civilit√©',
            profession STRING COMMENT 'Profession',
            specialite STRING COMMENT 'Sp√©cialit√©'
        )
        USING DELTA
        PARTITIONED BY (profession, specialite)
        LOCATION 's3a://healthcare-data/gold/dim_professionel'
    """)
    
    # =================================
    # TABLES DE FAITS
    # =================================
    
    # Table de faits des d√©c√®s
    logger.info("Cr√©ation de la table fait_deces...")
    spark.sql("""
        CREATE TABLE IF NOT EXISTS delta.`s3a://healthcare-data/gold/fait_deces` (
            fk_patient INT COMMENT 'Cl√© √©trang√®re patient',
            fk_date_deces INT COMMENT 'Cl√© √©trang√®re date de d√©c√®s',
            fk_lieu_deces INT COMMENT 'Cl√© √©trang√®re lieu de d√©c√®s',
            fk_lieu_naissance INT COMMENT 'Cl√© √©trang√®re lieu de naissance',
            nb_deces INT COMMENT 'Nombre de d√©c√®s agr√©g√©',
            annee INT COMMENT 'Ann√©e de partition'
        )   
        USING DELTA
        PARTITIONED BY (annee)
        LOCATION 's3a://healthcare-data/gold/fait_deces'
    """)
    
    # Table de faits des hospitalisations
    logger.info("Cr√©ation de la table fait_hospitalisation...")
    spark.sql("""
        CREATE TABLE IF NOT EXISTS delta.`s3a://healthcare-data/gold/fait_hospitalisation` (
            fk_patient INT COMMENT 'Cl√© √©trang√®re patient',
            fk_etablissement INT COMMENT 'Cl√© √©trang√®re √©tablissement',
            fk_diagnostic STRING COMMENT 'Cl√© √©trang√®re diagnostic',
            fk_date_entree INT COMMENT 'Cl√© √©trang√®re date d'entr√©e',
            duree_sejour_jours INT COMMENT 'Dur√©e du s√©jour (en jours)',
            nb_hospitalisations INT COMMENT 'Nombre d'hospitalisations (agr√©g√©)',
            annee INT COMMENT 'Ann√©e de partition'
        )
        USING DELTA
        PARTITIONED BY (annee)
        LOCATION 's3a://healthcare-data/gold/fait_hospitalisation'
    """)
    
    # Table de faits de la satisfaction des patients
    logger.info("Cr√©ation de la table fait_satisfaction...")
    spark.sql("""
        CREATE TABLE IF NOT EXISTS delta.`s3a://healthcare-data/gold/fait_satisfaction` (
            fk_etablissement INT COMMENT 'Cl√© √©trang√®re √©tablissement',
            fk_indicateur INT COMMENT 'Cl√© √©trang√®re indicateur',
            fk_date_mesure INT COMMENT 'Cl√© √©trang√®re date de mesure',
            score_ajuste FLOAT COMMENT 'Score ajust√© de satisfaction',
            nombre_reponses INT COMMENT 'Nombre total de r√©ponses',
            taux_participation FLOAT COMMENT 'Taux de participation (%)',
            annee INT COMMENT 'Ann√©e de partition'
        )   
        USING DELTA
        PARTITIONED BY (annee)
        LOCATION 's3a://healthcare-data/gold/fait_satisfaction'
    """)
    
    # Table de faits des consultations
    logger.info("Cr√©ation de la table fait_consultations...")
    spark.sql("""
        CREATE TABLE IF NOT EXISTS delta.`s3a://healthcare-data/gold/fait_consultations` (
            fk_patient INT COMMENT 'Cl√© √©trang√®re patient',
            fk_professionnel INT COMMENT 'Cl√© √©trang√®re professionnel de sant√©',
            fk_date_consultation INT COMMENT 'Cl√© √©trang√®re date de consultation',
            fk_diagnostic STRING COMMENT 'Cl√© √©trang√®re diagnostic',
            fk_etablissement INT COMMENT 'Cl√© √©trang√®re √©tablissement',
            duree_consultation_minutes INT COMMENT 'Dur√©e moyenne des consultations (en minutes)',
            nb_consultations INT COMMENT 'Nombre total de consultations',
            annee INT COMMENT 'Ann√©e de partition'
        )   
        USING DELTA
        PARTITIONED BY (annee)
        LOCATION 's3a://healthcare-data/gold/fait_consultations'
    """)
    
    logger.info("‚úÖ Toutes les tables Delta ont √©t√© cr√©√©es avec succ√®s!")

def verify_tables(spark):
    """V√©rifier que toutes les tables ont √©t√© cr√©√©es"""
    logger.info("üîç V√©rification des tables cr√©√©es...")
    
    tables = [
        "delta.`s3a://healthcare-data/delta/dim_lieu`",
        "delta.`s3a://healthcare-data/delta/dim_patient`",
        "delta.`s3a://healthcare-data/delta/dim_date`",
        "delta.`s3a://healthcare-data/delta/dim_etablissement`",
        "delta.`s3a://healthcare-data/delta/dim_diagnostic`",
        "delta.`s3a://healthcare-data/delta/dim_indicateur`",
        "delta.`s3a://healthcare-data/delta/dim_professionel`",
        "delta.`s3a://healthcare-data/delta/fait_deces`",
        "delta.`s3a://healthcare-data/delta/fait_hospitalisation`",
        "delta.`s3a://healthcare-data/delta/fait_satisfaction`",
        "delta.`s3a://healthcare-data/delta/fait_consultations`"
    ]
    
    for table in tables:
        try:
            table_name = table.split("/")[-1].replace("`", "")
            result = spark.sql(f"DESCRIBE {table}")
            logger.info(f"‚úÖ Table {table_name}: {result.count()} colonnes")
        except Exception as e:
            logger.error(f"‚ùå Erreur pour la table {table_name}: {str(e)}")

def main():
    """Fonction principale pour cr√©er les tables Delta"""
    spark = create_spark_session()
    
    try:
        logger.info("üöÄ D√©but de la cr√©ation des tables Delta Healthcare...")
        
        # Cr√©er toutes les tables
        create_delta_tables(spark)
        
        # V√©rifier les tables cr√©√©es
        verify_tables(spark)
        
        logger.info("üéâ Cr√©ation des tables Delta termin√©e avec succ√®s!")
        
    except Exception as e:
        logger.error(f"üí• Erreur lors de la cr√©ation des tables: {str(e)}")
        raise
    finally:
        spark.stop()

if __name__ == "__main__":
    main()